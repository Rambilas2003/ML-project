{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c4ad2-50fe-4e25-92f7-e3d62e3c64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "DATASET_PATH = \"dataset/spotify.csv\"\n",
    "MODEL_DIR = \"models\"\n",
    "TOKENIZER_PATH = os.path.join(MODEL_DIR, \"tokenizer.pkl\")\n",
    "KERAS_MODEL_PATH = os.path.join(MODEL_DIR, \"keras_model.h5\")\n",
    "PYTORCH_MODEL_PATH = os.path.join(MODEL_DIR, \"pytorch_model.pth\")\n",
    "MAX_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "#Load & Preprocess \n",
    "def load_and_preprocess_data():\n",
    "    df = pd.read_csv(DATASET_PATH)[['track_name', 'artist_name', 'lyrics']].dropna()\n",
    "    df['song_id'] = LabelEncoder().fit_transform(df['track_name'] + \" - \" + df['artist_name'])\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=MAX_WORDS, lower=True, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(df['lyrics'])\n",
    "    sequences = tokenizer.texts_to_sequences(df['lyrics'])\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "\n",
    "    with open(TOKENIZER_PATH, \"wb\") as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "    return df, padded_sequences, df['song_id']\n",
    "\n",
    "df, X, y = load_and_preprocess_data()\n",
    "\n",
    "# Train TensorFlow \n",
    "def train_keras_model():\n",
    "    model = Sequential([\n",
    "        Embedding(MAX_WORDS, 128, input_length=MAX_SEQUENCE_LENGTH),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(32),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(len(set(y)), activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(X, y, epochs=5, batch_size=32, validation_split=0.2)\n",
    "    model.save(KERAS_MODEL_PATH)\n",
    "\n",
    "if not os.path.exists(KERAS_MODEL_PATH):\n",
    "    train_keras_model()\n",
    "#Train PyTorch \n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        self.transformer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=4)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x.long())\n",
    "        x = self.transformer(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        return self.fc(x)\n",
    "\n",
    "def train_pytorch_model():\n",
    "    dataset = TensorDataset(torch.tensor(X, dtype=torch.float32), torch.tensor(y.values, dtype=torch.long))\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    model = TransformerModel(MAX_WORDS, 128, len(set(y)))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_X)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss.item()}\")\n",
    "\n",
    "    torch.save(model.state_dict(), PYTORCH_MODEL_PATH)\n",
    "\n",
    "if not os.path.exists(PYTORCH_MODEL_PATH):\n",
    "    train_pytorch_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5497f53d-3059-4cd8-93f9-f6bbe0824544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from train_models import TransformerModel, MAX_WORDS, MAX_SEQUENCE_LENGTH, TOKENIZER_PATH, KERAS_MODEL_PATH, PYTORCH_MODEL_PATH\n",
    "with open(TOKENIZER_PATH, \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# TensorFlow Model\n",
    "keras_model = tf.keras.models.load_model(KERAS_MODEL_PATH)\n",
    "\n",
    "# PyTorch Model\n",
    "pytorch_model = TransformerModel(MAX_WORDS, 128, 100)  # Adjust output size dynamically\n",
    "pytorch_model.load_state_dict(torch.load(PYTORCH_MODEL_PATH))\n",
    "pytorch_model.eval()\n",
    "\n",
    "# Prediction\n",
    "def predict_song(text_snippet):\n",
    "    sequence = tokenizer.texts_to_sequences([text_snippet])\n",
    "    padded_sequence = np.array(pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\"))\n",
    "\n",
    "    keras_pred = np.argmax(keras_model.predict(padded_sequence), axis=1)[0]\n",
    "    pytorch_pred = torch.argmax(pytorch_model(torch.tensor(padded_sequence, dtype=torch.long))).item()\n",
    "\n",
    "    return keras_pred, pytorch_pred\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text = input(\"ðŸŽµ Enter a song lyric snippet: \")\n",
    "    song_keras, song_pytorch = predict_song(text)\n",
    "    print(f\"\\nðŸŽ¶ TensorFlow Identified Song ID: {song_keras}\")\n",
    "    print(f\"ðŸŽ¶ PyTorch Identified Song ID: {song_pytorch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6206b-1c84-4d8e-992f-7ec44fbd96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from predict import predict_song\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    if \"text\" not in data:\n",
    "        return jsonify({\"error\": \"No text provided\"}), 400\n",
    "\n",
    "    keras_song, pytorch_song = predict_song(data[\"text\"])\n",
    "    return jsonify({\"TensorFlow\": keras_song, \"PyTorch\": pytorch_song})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b03d3-9bc5-4867-9449-f5ced6717682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
